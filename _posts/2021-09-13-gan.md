---
layout: post
title: Generative Adversarial Network
tags: [개념, Vision, GAN]
---

NLP에서 GAN구조를 적용한 논문들에 대한 리뷰를 올리려고 했는데, GAN에 대한 기본적인 설명을 따로 분리해서 작성해야 할 필요성을 느껴서 이렇게 따로 포스팅을 올리고자 한다.

GAN이라는 정말 재미있는 개념은 2014년에 [Generative Adversarial Nets](https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html) 논문으로부터 도입되었는데, vision분야에서 활용되다가 점차 NLP에도 많이 적용되고 있다.

이 포스팅에서는 NLP에서 GAN을 적용한 논문들을 다루기 위한 기본적인 개념만 다루고, vision분야에서 매우 고도화된 여러 이론들은 따로 다루지 않을 것이다.

# GAN이란?

GAN이라는 이름에 network 라는 단어가 들어있지만 이름과는 다르게 이는 어떤 모델을 지칭하는 것보단, 특별한 학습방법이라고 소개하는 것이 더 어울린다고 생각한다.

딥러닝에는 수많은 학습 방법들이 있지만, 대부분이 classification과 regression에 집중되어 있다. 정답 label을 가지고 가장 직관적으로 활용할 수 있으면서도, 좋은 결과를 가져오기 때문이다. 하지만 모든 태스크들이 이 classification과 regression에 어울리는 것은 아니다. 특히 정답을 특정한 label 하나로 표현하기 어려운 경우가 그런데, NLP에서는 이런 경우를 정말 많이 볼 수 있다. 예를 들어 번역같은 경우만 봐도 문장을 잘 번역한 결과는 여러가지가 있지만, 현재 대부분의 translation 데이터셋은 정답 label 한개를 가지고 평가하고 있다.

Reinforcement Learning 도 특별한 학습 방법중에 하나라고 볼 수 있다. 정답 label이 없는 대신 직접 reward 로직을 만들고, 이를 이용하는 loss와 함께 모델을 학습시키는 방식이다.

RL에 대해서 조금만 더 설명해보자면, 거의 모든 RL 방식들이 전부 두 개의 모델을 놓고서 학습시킨다.[^1] 정답 자체를 모르기 때문에, 처음에 정답을 찾아가는 과정 자체를 두 모델간의 output의 차이로부터 backpropagation이 일어나는 방식이다. 이렇게 두 개의 모델을 같이 학습시키는 방식은 상당히 수렴이 까다롭다. 그래서 RL도 label 없이 reward만으로 학습시킬 수 있다는 개념만 봤을때는 classification이나 regression보다 훨씬 좋은게 아닌가라는 생각이 들 수도 있지만, exploration 깊이가 깊어질수록 수렴이 까다롭고, RL에 적합한 environment의 조건들도 있기 때문에 아무 태스크에서나 활용하기는 어렵다.

RL에 대해서 설명한 이유는, GAN도 RL처럼 두 개의 모델을 이용해서 학습하는 방식이기 때문이다. 다른 점은, GAN은 정답 label을 이용한다는 것이다.

다시 말해서, GAN도 두 개의 모델을 같이 학습시키는 방식이기 때문에 수렴이 쉽지 않다. GAN이 vision분야에서 등장하고 발전된 이유가 바로 이런 이유라고 생각한다. 여러 딥러닝 분야 중에서 현재 vision분야가 비교적 모델이 CNN 기반 구조로 어느정도 완성되어있는 상태이기 때문에, 모델에 대해 신경을 덜 쓰고 다양한 시도를 해보기가 좋은 것이다. 현재는 이렇게 발전된 여러가지의 GAN을 가지고 NLP에서도 많이 적용하려는 시도가 있다.

[^1]: 정확히는 동일한 모델을 서로 다른 업데이트를 위해서 2개 모델로 적용

# GAN의 구조

GAN은 generator와 discriminator 두 개의 모델로 이루어져 있다. 이 두 모델이 서로 adversarial, 즉 적대적인 관계를 갖는데, 이는 다시 말해서 두 모델이 서로 경쟁하면서 성장해 나간다는 의미다. 두 모델이 어떤 식으로 성장해 나가는지, 구체적으로 살펴보도록 한다.

## Counterfeitors & Polices

GAN 논문에서는 이 generator와 discriminator모델에 대해서 counterfeitors(위조지폐 제작자)와 polices(경찰)에 비유해서 설명하고 있다. 두 모델의 목표는 다음과 같다.

- Generator (counterfeitors)
  - 어떤 입력이 주어지면, 입력에 대해서 정답 label과 같은 형태의 output을 만들어낸다. (위조지폐를 만들어 낸다.)
  - Generator의 목적은, discriminator (경찰)이 위조지폐(output)와 진짜 지폐(정답 label)를 구분할 수 없도록 정교한 지폐(output)를 만들어내는 것이다.
- Discriminator (polices)
  - 지폐(output)이 입력으로 들어오면, 그 지폐가 진짜인지 가짜인지를 구분한다. (True/False)
  - Discriminator의 목적은, 해당 입력이 generator가 만들어낸 것인지, 진짜 지폐(정답 label)인지를 정교하게 구분해내는 것이다.

이 두 모델이 서로 같이 성장해 나가는 것이 바로 GAN 모델의 핵심이 된다.

#### Distribution

원래 GAN 논문에서는 정답의 distribution과 분포를 맞춰가는 내용을 핵심으로 설명하고 있다. 하지만 결국에 이 distribution은 개념적으로만 존재하는 부분이기도 하고, 이후 여러 논문들에서 다양한 얘기가 되고 있다. 특히, NLP에서는 이 distribution에 대해 설명하기 자체가 쉽지 않다. 그래서 개인적으로는 이 distribution 은 GAN을 이해하는데 있어서 크게 중요하지 않다고 생각하여 이와 관련된 내용은 생략한다.

#### Generator의 입력

GAN 논문 기준으로는 random noise가 입력된다. 이 입력의 의미는 결국 어떤 위조 output을 만들어낼 것이냐에 대한 특성을 결정하고자 하는 것이다. 따라서 다양한 방식으로 입력이 주어질 수 있기 때문에, 지금은 입력 자체보다는 입력이 output의 특성을 결정하는 값이라는 정도의 의미만 갖는다고만 얘기하고 넘어가도록 한다.

## 학습 진행 방식

GAN의 학습 진행 방식은 다음과 같다. 구체적인 backpropagation 식은 개념에 있어서 중요하지 않아 생략한다. 원래 논문 이후로 다양한 방식이 생겨났기 때문이다.

- Generator는 자신이 만들어낸 output이 discriminator가 얼마나 fake로 구분했냐(위조지폐를 찾았냐)에 따라서 backpropagation이 이루어진다.
- Discriminator는 일정 확률로 진짜 label이 들어오거나, generator가 만들어낸 fake output이 입력으로 들어온다. 그러면 fake output을 진짜 label로 잘못 구분한 정도에 대해서 backpropagation이 이루어진다.

처음에는 generator 모델은 label과는 전혀 다른 엉뚱한 결과를 만들어 낼 것이다. 하지만 discriminator 또한 위조지폐와 정답 지폐를 구분하는 능력이 형편없기 때문에 둘이 비슷한 수준으로 경쟁이 될 것이다. 그리고 학습이 진행되면 generator 모델도 조금씩 발전하고, discriminator도 조금씩 발전해서 서로 퀄리티 있게 위조와 구분을 하게 되는 것이다.

이렇게 해서 최종적으로 generator도 더 이상 discriminator를 더 잘 속일 수 없고, discriminator도 더 이상 fake output을 완벽하게 구분해낼 수 없는 상태가 된다. 이 것이 GAN의 최종 수렴상태인데, 많은 논문들에서는 이를 Nash Equilibrium 이라고 표현하기도 한다.

### 수렴

두 개의 모델을 동시에 학습시켜야 하는 만큼, GAN도 수렴이 매우 어렵다. 특히, GAN의 수렴이 쉽지 않은 이유는 generator와 discriminator 모델자체가 서로 다른 구조이기 때문이다.

GAN을 수렴시키기 위해 가장 중요한 것은 서로 다른 모델이 비슷한 정도로 경쟁하고 발전해야 한다는 점이다. Generator가 너무 빨리 성장하면, discriminator는 진짜와 가짜를 구분하는 것을 배우기 어려워진다. 쉬운 위조지폐를 배우기도 전에, 바로 정교한 위조지폐를 줘 버리면 학습의 갈피를 못잡게 되는 것이다. 반대로 discriminator가 성장을 해도, generator는 학습이 어렵다. 위조지폐를 다 구분해버리는 discriminator때문에 어떤 방향으로 발전해야 할 지 알 수가 없어지는 것이다.

결국 이 두 모델이 서로 경쟁하면서 동반성장을 하고, nash equilibrium에 도달하는 것이 GAN 모델들의 과제라고 할 수 있다.

# GAN의 활용

GAN을 활용하려는 가장 큰 이유는 바로 classification이나 regression으로 학습할 수 없는 것들을 학습시키고 싶은 것이다.

1. Generator 모델 활용

   Generator 모델을 GAN을 통해서 학습시키는 방식이 좋은 이유는, 위에서도 얘기했듯이 다양한 정답을 학습시킬수 있다는 것이다.

   모델이 한 가지 종류의 정답 label만 뽑아내게 만드는 것이 목적이라면 굳이 GAN이 필요없을 것이다. 하지만 discriminator라는 개념의 등장으로, 꼭 정답이 아니더라도 "정답과 비슷한" 것들을 만들어내도 정답으로 인정된다는 점이 중요하다.

   이미지를 예로 들면, 정답 고양이 사진이 있을 때 기존에는 픽셀단위까지 똑같냐에 따라 구분했지만, 그냥 고양이가 들어가있는 비슷한 사진을 생성시키는 것도 학습시킬 수 있게 된다. 수식적으로 정답의 유사도를 구하는 방식보다 discriminator 방식으로 훨씬 유연하고 넓은 범위의 정답을 찾아낼 수 있게 된다.

   이렇게 generator를 학습시켜서 다양한 생성관련 모델에 활용할 수 있다.

2. Discriminator 모델 활용

   반대로, discriminator 모델을 사용하고자 GAN을 이용하기도 한다. 이 discriminator 모델 자체가 기존의 이미지 classification 모델과 같은 구조이기 때문이다. 특히, 잘만 활용하면 부족한 이미지 데이터를 generator로부터 data augmentation이 가능하기 때문에 동일한 dataset을 가지도고 유리하게 학습시킬 수 있다.

이후로는 NLP에서 이 GAN을 활용하는 관련 논문들을 다루도록 하겠다.

